{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7bd049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã đọc 59 link. Bắt đầu xử lý...\n",
      "[1/59] Đang tải: Ai tư vãn\n",
      "[2/59] Đang tải: Bác ơi!\n",
      "[3/59] Đang tải: Bài thơ về tiểu đội xe không kính\n",
      "[4/59] Đang tải: Bình Ngô đại cáo\n",
      "[5/59] Đang tải: Bông hồng cài áo\n",
      "[6/59] Đang tải: Cái mặt không chơi được\n",
      "[7/59] Đang tải: Câu chuyện đối đáp của người tiều phu ở núi Na\n",
      "[8/59] Đang tải: Châu bản triều Nguyễn\n",
      "[9/59] Đang tải: Chí Phèo\n",
      "[10/59] Đang tải: Chiếc thuyền ngoài xa\n",
      "[11/59] Đang tải: Chiếu thư đánh Chiêm\n",
      "[12/59] Đang tải: Chinh phụ ngâm\n",
      "[13/59] Đang tải: Chuyện người con gái Nam Xương\n",
      "[14/59] Đang tải: Công dư tiệp ký\n",
      "[15/59] Đang tải: Dế Mèn phiêu lưu ký\n",
      "[16/59] Đang tải: Đất nước đứng lên\n",
      "[17/59] Đang tải: Đất rừng phương Nam\n",
      "[18/59] Đang tải: Gia Định phú\n",
      "[19/59] Đang tải: Gia Định thất thủ vịnh\n",
      "[20/59] Đang tải: Hòn Đất (tiểu thuyết)\n",
      "[21/59] Đang tải: Hồn Trương Ba, da hàng thịt\n",
      "[22/59] Đang tải: Hương rừng Cà Mau\n",
      "[23/59] Đang tải: Kim Thạch kỳ duyên\n",
      "[24/59] Đang tải: Kính vạn hoa (truyện)\n",
      "[25/59] Đang tải: Làm đĩ (tiểu thuyết)\n",
      "[26/59] Đang tải: Làng (truyện ngắn)\n",
      "[27/59] Đang tải: Lão Hạc\n",
      "[28/59] Đang tải: Lặng lẽ Sa Pa\n",
      "[29/59] Đang tải: Lục súc tranh công\n",
      "[30/59] Đang tải: Lượm\n",
      "[31/59] Đang tải: Màu tím hoa sim\n",
      "[32/59] Đang tải: Mắt biếc (tiểu thuyết)\n",
      "[33/59] Đang tải: Mẫn Hiên thuyết loại\n",
      "[34/59] Đang tải: Nam Phong tạp chí\n",
      "[35/59] Đang tải: Nam quốc sơn hà\n",
      "[36/59] Đang tải: Ngày xưa có một chuyện tình\n",
      "[37/59] Đang tải: Những bóng người trên sân ga\n",
      "[38/59] Đang tải: Phạt Tống lộ bố văn\n",
      "[39/59] Đang tải: Quân trung từ mệnh tập\n",
      "[40/59] Đang tải: Sang thu\n",
      "[41/59] Đang tải: Số đỏ\n",
      "[42/59] Đang tải: Tắt đèn\n",
      "[43/59] Đang tải: Tắt lửa lòng\n",
      "[44/59] Đang tải: Thi nhân Việt Nam\n",
      "[45/59] Đang tải: Thư gửi các học sinh (Hồ Chí Minh, 1945)\n",
      "[46/59] Đang tải: Thư thất điều\n",
      "[47/59] Đang tải: Tôi thấy hoa vàng trên cỏ xanh\n",
      "[48/59] Đang tải: Tôi và chúng ta\n",
      "[49/59] Đang tải: Trại hoa vàng\n",
      "[50/59] Đang tải: Truyện Chân tướng quân\n",
      "[51/59] Đang tải: Truyện Kiều\n",
      "[52/59] Đang tải: Truyền kỳ mạn lục\n",
      "[53/59] Đang tải: Truyện thầy Lazaro Phiền\n",
      "[54/59] Đang tải: Tuyên ngôn độc lập (Việt Nam Dân chủ Cộng hòa)\n",
      "[55/59] Đang tải: Từ ấy (tập thơ)\n",
      "[56/59] Đang tải: Văn tế nghĩa sĩ Cần Giuộc\n",
      "[57/59] Đang tải: Văn tế tướng sĩ trận vong\n",
      "[58/59] Đang tải: Việt Bắc (bài thơ)\n",
      "[59/59] Đang tải: Vợ nhặt\n",
      "Xong! Kiểm tra file link_title_content.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse # Thư viện để xử lý link mã hóa\n",
    "\n",
    "# Tên file của bạn\n",
    "input_file = 'link_title.json'\n",
    "output_file = 'link_title_content.json'\n",
    "\n",
    "def get_wiki_content(url):\n",
    "    try:\n",
    "        # BƯỚC QUAN TRỌNG: Giải mã URL từ dạng %C6... sang tiếng Việt có dấu\n",
    "        # Ví dụ: .../Ai_t%C6%B0_v%C3%A3n -> .../Ai_tư_vãn\n",
    "        # Điều này giúp requests xử lý đường dẫn chính xác hơn\n",
    "        decoded_url = urllib.parse.unquote(url)\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        # Gọi request\n",
    "        response = requests.get(decoded_url, headers=headers, timeout=15)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return f\"Error: HTTP {response.status_code}\"\n",
    "            \n",
    "        # Sử dụng .content (byte) thay vì .text để tránh lỗi decode response\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        content_div = soup.find('div', {'id': 'mw-content-text'})\n",
    "        if not content_div:\n",
    "            return \"\"\n",
    "\n",
    "        parser_output = content_div.find('div', class_='mw-parser-output')\n",
    "        extracted_text = []\n",
    "        \n",
    "        if parser_output:\n",
    "            for element in parser_output.children:\n",
    "                # Dừng khi gặp phần Tham khảo\n",
    "                if element.name == 'h2':\n",
    "                    if element.find('span', {'id': 'Tham_khảo'}) or 'Tham khảo' in element.get_text():\n",
    "                        break\n",
    "\n",
    "                # Lấy nội dung\n",
    "                if element.name in ['p', 'h2', 'h3', 'h4']:\n",
    "                    text = element.get_text().strip()\n",
    "                    if text:\n",
    "                        extracted_text.append(text)\n",
    "                        \n",
    "        return \"\\n\\n\".join(extracted_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error Exception: {str(e)}\"\n",
    "\n",
    "# --- PHẦN CHẠY CHÍNH ---\n",
    "\n",
    "try:\n",
    "    # 1. Đọc file JSON với encoding='utf-8' (Bắt buộc để tránh lỗi decode tiếng Việt)\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(f\"Đã đọc {len(data)} link. Bắt đầu xử lý...\")\n",
    "\n",
    "    # 2. Vòng lặp\n",
    "    for index, item in enumerate(data):\n",
    "        print(f\"[{index+1}/{len(data)}] Đang tải: {item.get('text', 'No Title')}\")\n",
    "        \n",
    "        # Lấy link và xử lý\n",
    "        link = item.get('href', '')\n",
    "        if link:\n",
    "            item['content'] = get_wiki_content(link)\n",
    "        else:\n",
    "            item['content'] = \"\"\n",
    "\n",
    "    # 3. Lưu file kết quả cũng với encoding='utf-8'\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    print(f\"Xong! Kiểm tra file {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file {input_file}. Hãy chắc chắn file json nằm cùng thư mục code.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Lỗi: File {input_file} không đúng định dạng JSON.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi không xác định: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e12dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gốc: Đây là ví dụ [1] có tiếng Nhật 日本 và dấu \"ngoặc kép\".\n",
      "Xuống dòng.\n",
      "Sạch: Đây là ví dụ có tiếng Nhật 日本 và dấu ngoặc kép. Xuống dòng.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. Xóa các chú thích dạng [1], [12], [103]\n",
    "    # Regex: \\[ tìm dấu [, \\d+ tìm số, \\] tìm dấu ]\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    \n",
    "    # 2. Xóa dấu ngoặc kép \" (Thay bằng rỗng)\n",
    "    text = text.replace('\"', '')\n",
    "    \n",
    "    # 3. Xóa ký tự xuống dòng (Thay bằng khoảng trắng để nối chuỗi)\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    # 4. Xóa ký tự KHÔNG PHẢI Latinh/Tiếng Việt\n",
    "    # Logic: Tìm những ký tự KHÔNG nằm trong danh sách cho phép và thay bằng rỗng.\n",
    "    # Danh sách giữ lại: \n",
    "    # - \\w: Chữ cái và số (a-z, A-Z, 0-9)\n",
    "    # - \\s: Khoảng trắng\n",
    "    # - \\u00C0-\\u1EF9: Dải Unicode chứa các ký tự Tiếng Việt có dấu\n",
    "    # - .,!?:;()-_: Các dấu câu cơ bản\n",
    "    text = re.sub(r'[^\\w\\s\\u00C0-\\u1EF9.,!?;:()\\-]', '', text)\n",
    "    \n",
    "    # BƯỚC PHỤ: Chuẩn hóa khoảng trắng\n",
    "    # (Xóa khoảng trắng thừa do việc xóa ký tự để lại, ví dụ \"  \" thành \" \")\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test thử hàm với chuỗi rác\n",
    "test_str = 'Đây là ví dụ [1] có tiếng Nhật 日本 và dấu \"ngoặc kép\".\\nXuống dòng.'\n",
    "print(\"Gốc:\", test_str)\n",
    "print(\"Sạch:\", clean_text(test_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567e9fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý 59 dòng dữ liệu...\n",
      "✅ Đã tiền xử lý xong!\n",
      "\n",
      "--- Mẫu kết quả (Item 0) ---\n",
      "Ai tư vãn (chữ Hán: 哀思挽) là một tác phẩm trong văn chương Việt Nam, viết bằng chữ Nôm. Người ta tương truyền bài thơ này là do Bắc Cung Hoàng hậu Lê Ngọc Hân viết khóc phu quân là Quang Trung Hoàng đế...\n"
     ]
    }
   ],
   "source": [
    "# Tên file đầu vào và đầu ra\n",
    "input_file = 'link_title_content.json' # Thay tên file của bạn nếu khác\n",
    "output_file = 'link_title_clean.json'\n",
    "\n",
    "try:\n",
    "    # Đọc file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"Đang xử lý {len(data)} dòng dữ liệu...\")\n",
    "    \n",
    "    # Duyệt và làm sạch từng phần tử\n",
    "    count_processed = 0\n",
    "    for item in data:\n",
    "        original_content = item.get('content', '')\n",
    "        \n",
    "        # Gọi hàm clean_text đã định nghĩa ở trên\n",
    "        cleaned_content = clean_text(original_content)\n",
    "        \n",
    "        # Cập nhật lại vào json\n",
    "        item['content'] = cleaned_content\n",
    "        count_processed += 1\n",
    "\n",
    "    print(\"✅ Đã tiền xử lý xong!\")\n",
    "    \n",
    "    # Xem thử 1 mẫu kết quả đầu tiên\n",
    "    if len(data) > 0:\n",
    "        print(\"\\n--- Mẫu kết quả (Item 0) ---\")\n",
    "        print(data[0]['content'][:200] + \"...\") # In 200 ký tự đầu\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Lỗi: Không tìm thấy file '{input_file}'\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Lỗi: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c195bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã lưu file sạch vào: link_title_clean.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"✅ Đã lưu file sạch vào: {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Lỗi khi lưu file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a4575",
   "metadata": {},
   "source": [
    "# tác giả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "365006df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\vthuy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.4)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\vthuy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\vthuy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\vthuy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vthuy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vthuy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vthuy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vthuy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vthuy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vthuy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\vthuy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f044fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Tìm thấy 51 tác giả.\n",
      "--------------------------------------------------\n",
      "[1/51] Đang tải: Thâm Tâm ... -> Lấy được 27 câu.\n",
      "[2/51] Đang tải: Ngô Tất Tố ... -> Lấy được 68 câu.\n",
      "[3/51] Đang tải: Nam Trân ... -> Lấy được 16 câu.\n",
      "[4/51] Đang tải: Nguyễn Bính ... -> Lấy được 138 câu.\n",
      "[5/51] Đang tải: Dương Hướng ... -> Lấy được 13 câu.\n",
      "[6/51] Đang tải: Thu Bồn (nhà thơ) ... -> Lấy được 32 câu.\n",
      "[7/51] Đang tải: Nguyễn Văn Bổng (nhà văn) ... -> Lấy được 24 câu.\n",
      "[8/51] Đang tải: Văn Cao ... -> Lấy được 328 câu.\n",
      "[9/51] Đang tải: Vũ Đình Liên ... -> Lấy được 23 câu.\n",
      "[10/51] Đang tải: Hoàng Cầm (nhà thơ) ... -> Lấy được 28 câu.\n",
      "[11/51] Đang tải: Hoàng Nhuận Cầm ... -> Lấy được 12 câu.\n",
      "[12/51] Đang tải: Huy Cận ... -> Lấy được 35 câu.\n",
      "[13/51] Đang tải: Minh Chuyên (nhà văn) ... -> Lấy được 40 câu.\n",
      "[14/51] Đang tải: Xuân Diệu ... -> Lấy được 106 câu.\n",
      "[15/51] Đang tải: Phạm Tiến Duật ... -> Lấy được 26 câu.\n",
      "[16/51] Đang tải: Phạm Hoa ... -> Lấy được 18 câu.\n",
      "[17/51] Đang tải: Nguyễn Đức Mậu ... Lỗi HTTP 404\n",
      "[18/51] Đang tải: Quang Dũng ... -> Lấy được 1 câu.\n",
      "[19/51] Đang tải: Nguyễn Khoa Điềm ... Lỗi: HTTPSConnectionPool(host='vi.wikipedia.org', port=443): Read timed out. (read timeout=10)\n",
      "[20/51] Đang tải: Đoàn Giỏi ... -> Lấy được 29 câu.\n",
      "[21/51] Đang tải: Thanh Hải (nhà thơ) ... -> Lấy được 15 câu.\n",
      "[22/51] Đang tải: Tế Hanh ... -> Lấy được 22 câu.\n",
      "[23/51] Đang tải: Tô Hoài ... -> Lấy được 25 câu.\n",
      "[24/51] Đang tải: Nguyễn Công Hoan ... -> Lấy được 44 câu.\n",
      "[25/51] Đang tải: Nguyên Hồng ... -> Lấy được 32 câu.\n",
      "[26/51] Đang tải: Chính Hữu ... -> Lấy được 19 câu.\n",
      "[27/51] Đang tải: Tố Hữu ... -> Lấy được 65 câu.\n",
      "[28/51] Đang tải: Nguyễn Khải (nhà văn) ... -> Lấy được 24 câu.\n",
      "[29/51] Đang tải: Ma Văn Kháng ... -> Lấy được 27 câu.\n",
      "[30/51] Đang tải: Trần Đăng Khoa (nhà thơ) ... -> Lấy được 24 câu.\n",
      "[31/51] Đang tải: Vũ Khiêu ... -> Lấy được 46 câu.\n",
      "[32/51] Đang tải: Nguyễn Ngọc Ký ... -> Lấy được 27 câu.\n",
      "[33/51] Đang tải: Chu Lai (nhà văn) ... -> Lấy được 8 câu.\n",
      "[34/51] Đang tải: Kim Lân ... -> Lấy được 21 câu.\n",
      "[35/51] Đang tải: Trần Huy Liệu ... -> Lấy được 44 câu.\n",
      "[36/51] Đang tải: Thế Lữ ... -> Lấy được 332 câu.\n",
      "[37/51] Đang tải: Đặng Thai Mai ... -> Lấy được 33 câu.\n",
      "[38/51] Đang tải: Nguyễn Đăng Mạnh ... -> Lấy được 20 câu.\n",
      "[39/51] Đang tải: Tú Mỡ ... -> Lấy được 54 câu.\n",
      "[40/51] Đang tải: Thép Mới ... -> Lấy được 40 câu.\n",
      "[41/51] Đang tải: Vũ Tú Nam ... -> Lấy được 23 câu.\n",
      "[42/51] Đang tải: Nguyễn Thị Hồng Ngát ... -> Lấy được 47 câu.\n",
      "[43/51] Đang tải: Nguyên Ngọc ... -> Lấy được 41 câu.\n",
      "[44/51] Đang tải: Bảo Ninh ... -> Lấy được 21 câu.\n",
      "[45/51] Đang tải: Nguyễn Trọng Oánh ... -> Lấy được 29 câu.\n",
      "[46/51] Đang tải: Vũ Ngọc Phan ... -> Lấy được 30 câu.\n",
      "[47/51] Đang tải: Hoàng Ngọc Phách ... -> Lấy được 33 câu.\n",
      "[48/51] Đang tải: Hoàng Phủ Ngọc Tường ... -> Lấy được 35 câu.\n",
      "[49/51] Đang tải: Thanh Thảo (nhà thơ) ... -> Lấy được 14 câu.\n",
      "[50/51] Đang tải: Xuân Sách ... -> Lấy được 17 câu.\n",
      "[51/51] Đang tải: Hà Minh Tuân ... -> Lấy được 87 câu.\n",
      "--------------------------------------------------\n",
      "✅ THÀNH CÔNG! Đã lưu 2263 câu vào 'dataset_hoi_nha_van.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. INPUT HTML\n",
    "# ==============================================================================\n",
    "html_input = \"\"\"\n",
    "<div class=\"div-col\" style=\"column-width: 16em;\">\n",
    "<ul><li><a href=\"/wiki/Th%C3%A2m_T%C3%A2m\" title=\"Thâm Tâm\">Thâm Tâm</a></li>\n",
    "<li><a href=\"/wiki/Ng%C3%B4_T%E1%BA%A5t_T%E1%BB%91\" title=\"Ngô Tất Tố\">Ngô Tất Tố</a></li>\n",
    "<li><a href=\"/wiki/Nam_Tr%C3%A2n\" title=\"Nam Trân\">Nam Trân</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_B%C3%ADnh\" title=\"Nguyễn Bính\">Nguyễn Bính</a></li>\n",
    "<li><a href=\"/wiki/D%C6%B0%C6%A1ng_H%C6%B0%E1%BB%9Bng\" title=\"Dương Hướng\">Dương Hướng</a></li>\n",
    "<li><a href=\"/wiki/Thu_B%E1%BB%93n_(nh%C3%A0_th%C6%A1)\" title=\"Thu Bồn (nhà thơ)\">Thu Bồn</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_V%C4%83n_B%E1%BB%95ng_(nh%C3%A0_v%C4%83n)\" title=\"Nguyễn Văn Bổng (nhà văn)\">Nguyễn Văn Bổng</a></li>\n",
    "<li><a href=\"/wiki/V%C4%83n_Cao\" title=\"Văn Cao\">Văn Cao</a></li>\n",
    "<li><a href=\"/wiki/V%C5%A9_%C4%90%C3%ACnh_Li%C3%AAn\" title=\"Vũ Đình Liên\">Vũ Đình Liên</a></li>\n",
    "<li><a href=\"/wiki/Ho%C3%A0ng_C%E1%BA%A7m_(nh%C3%A0_th%C6%A1)\" title=\"Hoàng Cầm (nhà thơ)\">Hoàng Cầm</a></li>\n",
    "<li><a href=\"/wiki/Ho%C3%A0ng_Nhu%E1%BA%ADn_C%E1%BA%A7m\" title=\"Hoàng Nhuận Cầm\">Hoàng Nhuận Cầm</a></li>\n",
    "<li><a href=\"/wiki/Huy_C%E1%BA%ADn\" title=\"Huy Cận\">Huy Cận</a></li>\n",
    "<li><a href=\"/wiki/Minh_Chuy%C3%AAn_(nh%C3%A0_v%C4%83n)\" title=\"Minh Chuyên (nhà văn)\">Minh Chuyên</a></li>\n",
    "<li><a href=\"/wiki/Xu%C3%A2n_Di%E1%BB%87u\" title=\"Xuân Diệu\">Xuân Diệu</a></li>\n",
    "<li><a href=\"/wiki/Ph%E1%BA%A1m_Ti%E1%BA%BFn_Du%E1%BA%ADt\" title=\"Phạm Tiến Duật\">Phạm Tiến Duật</a></li>\n",
    "<li><a href=\"/wiki/Ph%E1%BA%A1m_Hoa\" title=\"Phạm Hoa\">Phạm Hoa</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_%C4%90%C4%83c_M%E1%BA%ADu\" title=\"Nguyễn Đức Mậu\">Nguyễn Đức Mậu</a></li>\n",
    "<li><a href=\"/wiki/Quang_D%C5%A9ng\" class=\"mw-disambig\" title=\"Quang Dũng\">Quang Dũng</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_Khoa_%C4%90i%E1%BB%81m\" title=\"Nguyễn Khoa Điềm\">Nguyễn Khoa Điềm</a></li>\n",
    "<li><a href=\"/wiki/%C4%90o%C3%A0n_Gi%E1%BB%8Fi\" title=\"Đoàn Giỏi\">Đoàn Giỏi</a></li>\n",
    "<li><a href=\"/wiki/Thanh_H%E1%BA%A3i_(nh%C3%A0_th%C6%A1)\" title=\"Thanh Hải (nhà thơ)\">Thanh Hải</a></li>\n",
    "<li><a href=\"/wiki/T%E1%BA%BF_Hanh\" title=\"Tế Hanh\">Tế Hanh</a></li>\n",
    "<li><a href=\"/wiki/T%C3%B4_Ho%C3%A0i\" title=\"Tô Hoài\">Tô Hoài</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_C%C3%B4ng_Hoan\" title=\"Nguyễn Công Hoan\">Nguyễn Công Hoan</a></li>\n",
    "<li><a href=\"/wiki/Nguy%C3%AAn_H%E1%BB%93ng\" title=\"Nguyên Hồng\">Nguyên Hồng</a></li>\n",
    "<li><a href=\"/wiki/Ch%C3%ADnh_H%E1%BB%AFu\" title=\"Chính Hữu\">Chính Hữu</a></li>\n",
    "<li><a href=\"/wiki/T%E1%BB%91_H%E1%BB%AFu\" title=\"Tố Hữu\">Tố Hữu</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_Kh%E1%BA%A3i_(nh%C3%A0_v%C4%83n)\" class=\"mw-redirect\" title=\"Nguyễn Khải (nhà văn)\">Nguyễn Khải</a></li>\n",
    "<li><a href=\"/wiki/Ma_V%C4%83n_Kh%C3%A1ng\" title=\"Ma Văn Kháng\">Ma Văn Kháng</a></li>\n",
    "<li><a href=\"/wiki/Tr%E1%BA%A7n_%C4%90%C4%83ng_Khoa_(nh%C3%A0_th%C6%A1)\" title=\"Trần Đăng Khoa (nhà thơ)\">Trần Đăng Khoa</a></li>\n",
    "<li><a href=\"/wiki/V%C5%A9_Khi%C3%AAu\" title=\"Vũ Khiêu\">Vũ Khiêu</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_Ng%E1%BB%8Dc_K%C3%BD\" title=\"Nguyễn Ngọc Ký\">Nguyễn Ngọc Ký</a></li>\n",
    "<li><a href=\"/wiki/Chu_Lai_(nh%C3%A0_v%C4%83n)\" title=\"Chu Lai (nhà văn)\">Chu Lai</a></li>\n",
    "<li><a href=\"/wiki/Kim_L%C3%A2n\" title=\"Kim Lân\">Kim Lân</a></li>\n",
    "<li><a href=\"/wiki/Tr%E1%BA%A7n_Huy_Li%E1%BB%87u\" title=\"Trần Huy Liệu\">Trần Huy Liệu</a></li>\n",
    "<li><a href=\"/wiki/Th%E1%BA%BF_L%E1%BB%AF\" title=\"Thế Lữ\">Thế Lữ</a></li>\n",
    "<li><a href=\"/wiki/%C4%90%E1%BA%B7ng_Thai_Mai\" title=\"Đặng Thai Mai\">Đặng Thai Mai</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_%C4%90%C4%83ng_M%E1%BA%A1nh\" title=\"Nguyễn Đăng Mạnh\">Nguyễn Đăng Mạnh</a></li>\n",
    "<li><a href=\"/wiki/T%C3%BA_M%E1%BB%A1\" title=\"Tú Mỡ\">Tú Mỡ</a></li>\n",
    "<li><a href=\"/wiki/Th%C3%A9p_M%E1%BB%9Bi\" title=\"Thép Mới\">Thép Mới</a></li>\n",
    "<li><a href=\"/wiki/V%C5%A9_T%C3%BA_Nam\" title=\"Vũ Tú Nam\">Vũ Tú Nam</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_Th%E1%BB%8B_H%E1%BB%93ng_Ng%C3%A1t\" title=\"Nguyễn Thị Hồng Ngát\">Nguyễn Thị Hồng Ngát</a></li>\n",
    "<li><a href=\"/wiki/Nguy%C3%AAn_Ng%E1%BB%8Dc\" title=\"Nguyên Ngọc\">Nguyên Ngọc</a></li>\n",
    "<li><a href=\"/wiki/B%E1%BA%A3o_Ninh\" title=\"Bảo Ninh\">Bảo Ninh</a></li>\n",
    "<li><a href=\"/wiki/Nguy%E1%BB%85n_Tr%E1%BB%8Dng_O%C3%A1nh\" title=\"Nguyễn Trọng Oánh\">Nguyễn Trọng Oánh</a></li>\n",
    "<li><a href=\"/wiki/V%C5%A9_Ng%E1%BB%8Dc_Phan\" title=\"Vũ Ngọc Phan\">Vũ Ngọc Phan</a></li>\n",
    "<li><a href=\"/wiki/Ho%C3%A0ng_Ng%E1%BB%8Dc_Ph%C3%A1ch\" title=\"Hoàng Ngọc Phách\">Hoàng Ngọc Phách</a></li>\n",
    "<li><a href=\"/wiki/Ho%C3%A0ng_Ph%E1%BB%A7_Ng%E1%BB%8Dc_T%C6%B0%E1%BB%9Dng\" title=\"Hoàng Phủ Ngọc Tường\">Hoàng Phủ Ngọc Tường</a></li>\n",
    "<li><a href=\"/wiki/Thanh_Th%E1%BA%A3o_(nh%C3%A0_th%C6%A1)\" title=\"Thanh Thảo (nhà thơ)\">Thanh Thảo</a></li>\n",
    "<li><a href=\"/wiki/Xu%C3%A2n_S%C3%A1ch\" title=\"Xuân Sách\">Xuân Sách</a></li>\n",
    "<li><a href=\"/wiki/H%C3%A0_Minh_Tu%C3%A2n\" title=\"Hà Minh Tuân\">Hà Minh Tuân</a></li></ul>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. CẤU HÌNH & HÀM XỬ LÝ\n",
    "# ==============================================================================\n",
    "BASE_URL = \"https://vi.wikipedia.org\"\n",
    "OUTPUT_FILE = \"dataset_hoi_nha_van.json\"\n",
    "\n",
    "# GIẢ LẬP TRÌNH DUYỆT (QUAN TRỌNG)\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "def get_links_from_html(html_str):\n",
    "    soup = BeautifulSoup(html_str, 'html.parser')\n",
    "    links = []\n",
    "    a_tags = soup.select('li a')\n",
    "    for a in a_tags:\n",
    "        href = a.get('href')\n",
    "        title = a.get('title')\n",
    "        if href and href.startswith('/wiki/') and 'redlink' not in href:\n",
    "            full_link = BASE_URL + href\n",
    "            links.append({\"name\": title, \"url\": full_link})\n",
    "    \n",
    "    # Lọc trùng lặp\n",
    "    unique_links = {v['url']: v for v in links}.values()\n",
    "    return list(unique_links)\n",
    "\n",
    "def scrape_and_split_content(author_list):\n",
    "    final_dataset = []\n",
    "    global_id = 1\n",
    "    total = len(author_list)\n",
    "    \n",
    "    print(f\"-> Tìm thấy {total} tác giả.\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, author in enumerate(author_list):\n",
    "        url = author['url']\n",
    "        name = author['name']\n",
    "        \n",
    "        print(f\"[{i+1}/{total}] Đang tải: {name} ... \", end=\"\")\n",
    "        \n",
    "        try:\n",
    "            # THÊM HEADERS VÀO YÊU CẦU\n",
    "            response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"Lỗi HTTP {response.status_code}\")\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Lấy tất cả thẻ p trong nội dung chính\n",
    "            # Wikipedia thường dùng div mw-parser-output bên trong mw-content-text\n",
    "            content_div = soup.find('div', {'id': 'mw-content-text'})\n",
    "            if not content_div:\n",
    "                print(\"Không tìm thấy nội dung.\")\n",
    "                continue\n",
    "\n",
    "            paragraphs = content_div.find_all('p')\n",
    "            \n",
    "            count_local = 0\n",
    "            for p in paragraphs:\n",
    "                text = p.get_text()\n",
    "                # Cleaning\n",
    "                text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "                text = re.sub(r'\\s+', ' ', text).strip()\n",
    "                \n",
    "                if not text: continue\n",
    "                \n",
    "                # Splitting\n",
    "                sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "                \n",
    "                for sent in sentences:\n",
    "                    # Giảm điều kiện lọc xuống 15 ký tự để bắt được nhiều hơn\n",
    "                    if len(sent) > 15:\n",
    "                        final_dataset.append({\n",
    "                            \"id\": global_id,\n",
    "                            \"source\": name,\n",
    "                            \"text\": sent\n",
    "                        })\n",
    "                        global_id += 1\n",
    "                        count_local += 1\n",
    "            \n",
    "            print(f\"-> Lấy được {count_local} câu.\")\n",
    "            time.sleep(0.2) # Nghỉ nhẹ\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi: {e}\")\n",
    "            continue\n",
    "            \n",
    "    print(\"-\" * 50)\n",
    "    return final_dataset\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. MAIN\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    authors = get_links_from_html(html_input)\n",
    "    \n",
    "    if authors:\n",
    "        dataset = scrape_and_split_content(authors)\n",
    "        \n",
    "        if len(dataset) > 0:\n",
    "            with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "                json.dump(dataset, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"✅ THÀNH CÔNG! Đã lưu {len(dataset)} câu vào '{OUTPUT_FILE}'.\")\n",
    "        else:\n",
    "            print(\"⚠️ Vẫn không lấy được câu nào. Hãy kiểm tra lại kết nối mạng.\")\n",
    "    else:\n",
    "        print(\"Không parse được HTML đầu vào.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "751c4b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số câu ban đầu: 2263\n",
      "------------------------------\n",
      "Đã xử lý xong!\n",
      "File gốc: 2263 câu\n",
      "File mới: 913 câu (đã lưu tại 'dataset_hoi_nha_van_final.json')\n",
      "------------------------------\n",
      "Thống kê số lượng câu per tác giả (Top 5):\n",
      "- Thâm Tâm: 20 câu\n",
      "- Ngô Tất Tố: 20 câu\n",
      "- Nam Trân: 16 câu\n",
      "- Nguyễn Bính: 20 câu\n",
      "- Dương Hướng: 13 câu\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "input_file = 'dataset_hoi_nha_van.json'\n",
    "output_file = 'dataset_hoi_nha_van_final.json'\n",
    "\n",
    "def limit_sentences_per_author(input_path, output_path, max_sentences=20):\n",
    "    try:\n",
    "        # 1. Đọc dữ liệu\n",
    "        if not os.path.exists(input_path):\n",
    "            print(f\"Lỗi: Không tìm thấy file {input_path}\")\n",
    "            return\n",
    "\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"Tổng số câu ban đầu: {len(data)}\")\n",
    "        \n",
    "        # 2. Lọc dữ liệu\n",
    "        filtered_data = []\n",
    "        author_counts = {} # Biến đếm số câu của từng tác giả\n",
    "        new_id = 1\n",
    "        \n",
    "        for item in data:\n",
    "            author = item.get('source', 'Unknown')\n",
    "            \n",
    "            # Khởi tạo đếm nếu gặp tác giả mới\n",
    "            if author not in author_counts:\n",
    "                author_counts[author] = 0\n",
    "            \n",
    "            # Kiểm tra điều kiện: Chưa đủ 30 câu thì lấy\n",
    "            if author_counts[author] < max_sentences:\n",
    "                # Tạo bản ghi mới để đánh lại ID luôn cho đẹp\n",
    "                new_item = {\n",
    "                    \"id\": new_id,\n",
    "                    \"source\": author,\n",
    "                    \"text\": item['text']\n",
    "                }\n",
    "                filtered_data.append(new_item)\n",
    "                \n",
    "                # Tăng biến đếm và ID\n",
    "                author_counts[author] += 1\n",
    "                new_id += 1\n",
    "        \n",
    "        # 3. Lưu file mới\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(filtered_data, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Đã xử lý xong!\")\n",
    "        print(f\"File gốc: {len(data)} câu\")\n",
    "        print(f\"File mới: {len(filtered_data)} câu (đã lưu tại '{output_path}')\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # In thống kê chi tiết vài tác giả để kiểm tra\n",
    "        print(\"Thống kê số lượng câu per tác giả (Top 5):\")\n",
    "        for auth, count in list(author_counts.items())[:5]:\n",
    "            print(f\"- {auth}: {count} câu\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Có lỗi xảy ra: {e}\")\n",
    "\n",
    "# --- CHẠY ---\n",
    "limit_sentences_per_author(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
