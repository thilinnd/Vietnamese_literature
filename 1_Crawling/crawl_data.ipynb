{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef859d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import os\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb48fe",
   "metadata": {},
   "source": [
    "# Tải dữ liệu tác phẩm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876b1bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thư mục dữ liệu: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\n",
      " File input: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\link_href.csv\n",
      " File output: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\wiki_data.json\n"
     ]
    }
   ],
   "source": [
    "current_folder = os.getcwd()\n",
    "data_folder_path = os.path.abspath(os.path.join(current_folder, '..', 'Data'))\n",
    "\n",
    "# Đường dẫn file đầu vào và đầu ra\n",
    "input_file_path = os.path.join(data_folder_path, 'link_href.csv')\n",
    "output_file_path = os.path.join(data_folder_path, 'wiki_data.json')\n",
    "\n",
    "# Header giả lập trình duyệt\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "print(f\" Thư mục dữ liệu: {data_folder_path}\")\n",
    "print(f\" File input: {input_file_path}\")\n",
    "print(f\" File output: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671cedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Hàm làm sạch sơ bộ văn bản\"\"\"\n",
    "    # Xóa khoảng trắng thừa (ví dụ: \"  \" -> \" \")\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def get_wiki_content_optimized(url):\n",
    "    try:\n",
    "        # Giải mã URL\n",
    "        decoded_url = urllib.parse.unquote(url)\n",
    "        \n",
    "        response = requests.get(decoded_url, headers=headers, timeout=15)\n",
    "        if response.status_code != 200:\n",
    "            return None \n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # 1. Tìm vùng nội dung chính\n",
    "        content_div = soup.find('div', {'id': 'mw-content-text'})\n",
    "        if not content_div:\n",
    "            return \"\"\n",
    "\n",
    "        # 2. LÀM SẠCH HTML\n",
    "        # Xóa số mũ tham khảo [1], [2]...\n",
    "        for tag in content_div.find_all('sup', class_='reference'):\n",
    "            tag.decompose()\n",
    "            \n",
    "        # Xóa bảng thông tin, điều hướng, mục lục\n",
    "        for tag in content_div.find_all(['table', 'div'], class_=['infobox', 'navbox', 'toc', 'mw-empty-elt']):\n",
    "            tag.decompose()\n",
    "            \n",
    "        # Xóa các nút \"sửa\"\n",
    "        for tag in content_div.find_all('span', class_='mw-editsection'):\n",
    "            tag.decompose()\n",
    "\n",
    "        # 3. TRÍCH XUẤT NỘI DUNG\n",
    "        parser_output = content_div.find('div', class_='mw-parser-output')\n",
    "        extracted_text = []\n",
    "        \n",
    "        if parser_output:\n",
    "            stop_keywords = ['tham khảo', 'chú thích', 'liên kết ngoài', 'xem thêm', 'đọc thêm']\n",
    "            \n",
    "            for element in parser_output.children:\n",
    "                if element.name is None: continue\n",
    "\n",
    "                # Kiểm tra điểm dừng\n",
    "                if element.name in ['h2', 'h3']:\n",
    "                    header_text = element.get_text().lower()\n",
    "                    if any(kw in header_text for kw in stop_keywords):\n",
    "                        break \n",
    "                \n",
    "                # Lấy nội dung\n",
    "                if element.name in ['p', 'h2', 'h3', 'h4', 'ul', 'ol', 'dl']:\n",
    "                    text = element.get_text(separator=' ').strip()\n",
    "                    clean_t = clean_text(text)\n",
    "                    if clean_t:\n",
    "                        extracted_text.append(clean_t)\n",
    "\n",
    "        return \"\\n\\n\".join(extracted_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi ngoại lệ khi crawl {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb957ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Đang đọc file CSV và bắt đầu xử lý...\n",
      " Tìm thấy tổng cộng 110 dòng trong file.\n",
      "[1/57] ⏳ Đang tải: Ai tư vãn...  Thành công (560 ký tự)\n",
      "[2/57] ⏳ Đang tải: Bác ơi!...  Thành công (1346 ký tự)\n",
      "[3/57] ⏳ Đang tải: Bài thơ về tiểu đội xe không kính...  Thành công (647 ký tự)\n",
      "[4/57] ⏳ Đang tải: Bình Ngô đại cáo...  Thành công (1466 ký tự)\n",
      "[5/57] ⏳ Đang tải: Bông hồng cài áo...  Thành công (1984 ký tự)\n",
      "[6/57] ⏳ Đang tải: Cái mặt không chơi được...  Thành công (879 ký tự)\n",
      "[7/57] ⏳ Đang tải: Câu chuyện đối đáp của người tiều phu ở núi Na...  Thành công (646 ký tự)\n",
      "[8/57] ⏳ Đang tải: Châu bản triều Nguyễn...  Thành công (5400 ký tự)\n",
      "[9/57] ⏳ Đang tải: Chí Phèo...  Thành công (306 ký tự)\n",
      "[10/57] ⏳ Đang tải: Chiếc thuyền ngoài xa...  Thành công (575 ký tự)\n",
      "[11/57] ⏳ Đang tải: Chiếu thư đánh Chiêm...  Thành công (208 ký tự)\n",
      "[12/57] ⏳ Đang tải: Chinh phụ ngâm...  Thành công (446 ký tự)\n",
      "[13/57] ⏳ Đang tải: Chuyện người con gái Nam Xương...  Thành công (343 ký tự)\n",
      "[14/57] ⏳ Đang tải: Công dư tiệp ký...  Thành công (223 ký tự)\n",
      "[15/57] ⏳ Đang tải: Dế Mèn phiêu lưu ký...  Thành công (1469 ký tự)\n",
      "[16/57] ⏳ Đang tải: Đất nước đứng lên...  Thành công (123 ký tự)\n",
      "[17/57] ⏳ Đang tải: Đất rừng phương Nam...  Thất bại hoặc không có nội dung\n",
      "[18/57] ⏳ Đang tải: Gia Định phú...  Thành công (350 ký tự)\n",
      "[19/57] ⏳ Đang tải: Gia Định thất thủ vịnh...  Thành công (216 ký tự)\n",
      "[20/57] ⏳ Đang tải: Hòn Đất (tiểu thuyết)...  Thành công (313 ký tự)\n",
      "[21/57] ⏳ Đang tải: Hương rừng Cà Mau...  Thành công (196 ký tự)\n",
      "[22/57] ⏳ Đang tải: Kim Thạch kỳ duyên...  Thành công (295 ký tự)\n",
      "[23/57] ⏳ Đang tải: Kính vạn hoa (truyện)...  Thành công (1061 ký tự)\n",
      "[24/57] ⏳ Đang tải: Làm đĩ (tiểu thuyết)...  Thành công (209 ký tự)\n",
      "[25/57] ⏳ Đang tải: Làng (truyện ngắn)...  Thành công (384 ký tự)\n",
      "[26/57] ⏳ Đang tải: Lão Hạc...  Thành công (493 ký tự)\n",
      "[27/57] ⏳ Đang tải: Lặng lẽ Sa Pa...  Thành công (615 ký tự)\n",
      "[28/57] ⏳ Đang tải: Lục súc tranh công...  Thành công (240 ký tự)\n",
      "[29/57] ⏳ Đang tải: Lượm...  Thành công (567 ký tự)\n",
      "[30/57] ⏳ Đang tải: Màu tím hoa sim...  Thành công (6193 ký tự)\n",
      "[31/57] ⏳ Đang tải: Mắt biếc (tiểu thuyết)...  Thành công (2544 ký tự)\n",
      "[32/57] ⏳ Đang tải: Mẫn Hiên thuyết loại...  Thành công (1695 ký tự)\n",
      "[33/57] ⏳ Đang tải: Nam Phong tạp chí...  Thành công (905 ký tự)\n",
      "[34/57] ⏳ Đang tải: Nam quốc sơn hà...  Thành công (776 ký tự)\n",
      "[35/57] ⏳ Đang tải: Ngày xưa có một chuyện tình...  Thành công (575 ký tự)\n",
      "[36/57] ⏳ Đang tải: Những bóng người trên sân ga...  Thành công (127 ký tự)\n",
      "[37/57] ⏳ Đang tải: Phạt Tống lộ bố văn...  Thành công (248 ký tự)\n",
      "[38/57] ⏳ Đang tải: Quân trung từ mệnh tập...  Thành công (1088 ký tự)\n",
      "[39/57] ⏳ Đang tải: Sang thu...  Thành công (261 ký tự)\n",
      "[40/57] ⏳ Đang tải: Số đỏ...  Thành công (1199 ký tự)\n",
      "[41/57] ⏳ Đang tải: Tắt đèn...  Thành công (524 ký tự)\n",
      "[42/57] ⏳ Đang tải: Tắt lửa lòng...  Thất bại hoặc không có nội dung\n",
      "[43/57] ⏳ Đang tải: Thi nhân Việt Nam...  Thành công (622 ký tự)\n",
      "[44/57] ⏳ Đang tải: Thư thất điều...  Thành công (663 ký tự)\n",
      "[45/57] ⏳ Đang tải: Tôi thấy hoa vàng trên cỏ xanh...  Thành công (6665 ký tự)\n",
      "[46/57] ⏳ Đang tải: Tôi và chúng ta...  Thành công (143 ký tự)\n",
      "[47/57] ⏳ Đang tải: Trại hoa vàng...  Thất bại hoặc không có nội dung\n",
      "[48/57] ⏳ Đang tải: Truyện Chân tướng quân...  Thành công (174 ký tự)\n",
      "[49/57] ⏳ Đang tải: Truyện Kiều...  Thành công (320 ký tự)\n",
      "[50/57] ⏳ Đang tải: Truyền kỳ mạn lục...  Thành công (766 ký tự)\n",
      "[51/57] ⏳ Đang tải: Truyện thầy Lazaro Phiền...  Thành công (2802 ký tự)\n",
      "[52/57] ⏳ Đang tải: Tuyên ngôn độc lập (Việt Nam Dân chủ Cộng hòa)...  Thành công (338 ký tự)\n",
      "[53/57] ⏳ Đang tải: Từ ấy (tập thơ)...  Thành công (451 ký tự)\n",
      "[54/57] ⏳ Đang tải: Văn tế nghĩa sĩ Cần Giuộc...  Thành công (196 ký tự)\n",
      "[55/57] ⏳ Đang tải: Văn tế tướng sĩ trận vong...  Thành công (183 ký tự)\n",
      "[56/57] ⏳ Đang tải: Việt Bắc (bài thơ)...  Thành công (262 ký tự)\n",
      "[57/57] ⏳ Đang tải: Vợ nhặt...  Thành công (538 ký tự)\n",
      "\n",
      " Đã đạt giới hạn 57 link đầu tiên. Dừng xử lý các link còn lại.\n",
      "\n",
      "Đang lưu 54 mục vào: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\wiki_data.json\n",
      "HOÀN TẤT!\n"
     ]
    }
   ],
   "source": [
    "final_data = []\n",
    "LINK_LIMIT = 57  \n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    print(\"\\n Đang đọc file CSV và bắt đầu xử lý...\")\n",
    "    \n",
    "    with open(input_file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(f\" Tìm thấy tổng cộng {len(lines)} dòng trong file.\")\n",
    "    \n",
    "    processed_count = 0 # Biến đếm số link đã xử lý\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        \n",
    "        # Xử lý tách cột\n",
    "        parts = line.split(',')\n",
    "        if len(parts) < 2:\n",
    "            parts = line.split(';')\n",
    "            \n",
    "        if len(parts) >= 2:\n",
    "            name = parts[0].strip().replace('\"', '')\n",
    "            url = parts[-1].strip().replace('\"', '')\n",
    "            \n",
    "            # Bỏ qua tiêu đề hoặc link hỏng\n",
    "            if \"http\" not in url:\n",
    "                continue\n",
    "\n",
    "            if processed_count >= LINK_LIMIT:\n",
    "                print(f\"\\n Đã đạt giới hạn {LINK_LIMIT} link đầu tiên. Dừng xử lý các link còn lại.\")\n",
    "                break\n",
    "\n",
    "            print(f\"[{processed_count + 1}/{LINK_LIMIT}] ⏳ Đang tải: {name}...\", end=\" \")\n",
    "            \n",
    "            content = get_wiki_content_optimized(url)\n",
    "            \n",
    "            if content:\n",
    "                final_data.append({\n",
    "                    \"ten_tac_gia\": name,\n",
    "                    \"link\": url,\n",
    "                    \"noi_dung\": content\n",
    "                })\n",
    "                print(f\" Thành công ({len(content)} ký tự)\")\n",
    "            else:\n",
    "                print(\" Thất bại hoặc không có nội dung\")\n",
    "            \n",
    "            processed_count += 1\n",
    "                \n",
    "    if final_data:\n",
    "        print(f\"\\nĐang lưu {len(final_data)} mục vào: {output_file_path}\")\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_data, f, ensure_ascii=False, indent=4)\n",
    "        print(\"HOÀN TẤT!\")\n",
    "    else:\n",
    "        print(\" Không lấy được dữ liệu nào.\")\n",
    "\n",
    "else:\n",
    "    print(f\" LỖI: Không tìm thấy file đầu vào tại: {input_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c65391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(text):\n",
    "    \"\"\"\n",
    "    Hàm làm sạch một câu văn:\n",
    "    - Xóa ký tự xuống dòng\n",
    "    - Xóa số tham chiếu [1] nếu còn sót\n",
    "    - Xóa các ký tự đặc biệt rác (giữ lại tiếng Việt và dấu câu chuẩn)\n",
    "    - Chuẩn hóa khoảng trắng\n",
    "    \"\"\"\n",
    "    # 1. Xóa xuống dòng\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    # 2. Xóa số mũ tham chiếu dạng [1], [12] (đề phòng còn sót)\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    \n",
    "    # 3. Giữ lại: Chữ cái (bao gồm tiếng Việt), số, khoảng trắng, và các dấu câu cơ bản (. , ? ! ; : \" - ( ))\n",
    "    # Loại bỏ các ký tự lạ như @ # $ % ^ & * ...\n",
    "    text = re.sub(r'[^\\w\\s\\.,\\?!\\;:\"\\-\\(\\)\\u00C0-\\u1EF9]', ' ', text)\n",
    "    \n",
    "    # 4. Xóa khoảng trắng thừa (ví dụ \"  \" -> \" \")\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"\n",
    "    Tách đoạn văn thành danh sách các câu dựa vào dấu chấm, hỏi, cảm thán.\n",
    "    Sử dụng Lookbehind (?<=...) để giữ lại dấu câu ở cuối câu.\n",
    "    \"\"\"\n",
    "    # Tách khi gặp . ! ? theo sau là khoảng trắng hoặc hết dòng\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = os.path.join(data_folder_path, 'wiki_data.json')\n",
    "output_file_path = os.path.join(data_folder_path, 'wiki_sentences_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697dc23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Đang đọc file JSON và xử lý tách câu...\n",
      " Tìm thấy 54 bài viết gốc.\n",
      "\n",
      " Đã tách và làm sạch được: 386 câu.\n",
      " Đang ghi file...\n",
      " HOÀN TẤT! File json mới đã sẵn sàng.\n",
      "\n",
      "--- [XEM THỬ 5 CÂU ĐẦU TIÊN] ---\n",
      "[\n",
      "    {\n",
      "        \"ten_tac_gia\": \"Ai tư vãn\",\n",
      "        \"cau_van\": \"Ai tư vãn ( chữ Hán : 哀思挽) là một tác phẩm trong văn chương Việt Nam , viết bằng chữ Nôm .\"\n",
      "    },\n",
      "    {\n",
      "        \"ten_tac_gia\": \"Ai tư vãn\",\n",
      "        \"cau_van\": \"Người ta tương truyền bài thơ này là do Bắc Cung Hoàng hậu Lê Ngọc Hân viết khóc phu quân là Quang Trung Hoàng đế Nguyễn Huệ .\"\n",
      "    },\n",
      "    {\n",
      "        \"ten_tac_gia\": \"Ai tư vãn\",\n",
      "        \"cau_van\": \"Theo ý kiến của Thuần Phong đã nói trong sách \\\"Chinh phụ ngâm khúc giảng luận\\\" (do Á Châu xuất bản), bài thơ này có chịu ảnh hưởng bản dịch Chinh phụ ngâm của bà Đoàn Thị Điểm .\"\n",
      "    },\n",
      "    {\n",
      "        \"ten_tac_gia\": \"Ai tư vãn\",\n",
      "        \"cau_van\": \"Đây là một tác phẩm văn vần viết theo thể \\\"ngâm\\\" , tức song thất lục bát gồm 164 câu, hay đúng ra là 164 dòng.\"\n",
      "    },\n",
      "    {\n",
      "        \"ten_tac_gia\": \"Ai tư vãn\",\n",
      "        \"cau_van\": \"Ai tư vãn của Ngọc Hân Công chúa liên kết hỏng\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    print(\"\\n Đang đọc file JSON và xử lý tách câu...\")\n",
    "    \n",
    "    try:\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "            raw_data = json.load(f)\n",
    "            \n",
    "        print(f\" Tìm thấy {len(raw_data)} bài viết gốc.\")\n",
    "        \n",
    "        total_sentences = 0\n",
    "        \n",
    "        for entry in raw_data:\n",
    "            author_name = entry.get('ten_tac_gia', 'Unknown')\n",
    "            full_content = entry.get('noi_dung', '')\n",
    "            \n",
    "            # Bước 1: Tách thành các câu lẻ\n",
    "            sentences_list = split_into_sentences(full_content)\n",
    "            \n",
    "            for sent in sentences_list:\n",
    "                # Bước 2: Làm sạch câu\n",
    "                cleaned_sent = clean_sentence(sent)\n",
    "                \n",
    "                # Bước 3: Lọc rác (Chỉ lấy câu có độ dài > 10 ký tự và bắt đầu bằng chữ hoa)\n",
    "                # Điều kiện len > 10 giúp loại bỏ các tiêu đề ngắn hoặc vụn vặt\n",
    "                if len(cleaned_sent) > 10:\n",
    "                    processed_data.append({\n",
    "                        \"ten_tac_gia\": author_name,\n",
    "                        \"cau_van\": cleaned_sent\n",
    "                    })\n",
    "                    total_sentences += 1\n",
    "\n",
    "        # Lưu kết quả\n",
    "        print(f\"\\n Đã tách và làm sạch được: {total_sentences} câu.\")\n",
    "        print(f\" Đang ghi file...\")\n",
    "        \n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        print(\" HOÀN TẤT! File json mới đã sẵn sàng.\")\n",
    "        \n",
    "        # In thử 5 câu đầu tiên để kiểm tra\n",
    "        if processed_data:\n",
    "            print(\"\\n--- [XEM THỬ 5 CÂU ĐẦU TIÊN] ---\")\n",
    "            print(json.dumps(processed_data[:5], ensure_ascii=False, indent=4))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Lỗi khi xử lý: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934422d",
   "metadata": {},
   "source": [
    "# Tải dữ liệu tác giả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "852cd4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = os.getcwd()\n",
    "data_folder_path = os.path.abspath(os.path.join(current_folder, '..', 'Data'))\n",
    "\n",
    "input_file_path = os.path.join(data_folder_path, 'wiki_data.json')\n",
    "\n",
    "output_file_path = os.path.join(data_folder_path, 'wiki_sentences_2.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ed48b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đọc dữ liệu thô từ: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\wiki_data.json\n",
      "Lưu dữ liệu câu sạch vào: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\wiki_sentences_2.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Đọc dữ liệu thô từ: {input_file_path}\")\n",
    "print(f\"Lưu dữ liệu câu sạch vào: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c6c3395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " File Input: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\wiki_data.json\n",
      " File Output (Ghi tiếp): d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\wiki_sentences_2.json\n",
      " Bỏ qua: 57 link.\n",
      " Xử lý tiếp: 51 link.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "SKIP_COUNT = 57     # Bỏ qua 56 link đầu\n",
    "TAKE_COUNT = 51     # Lấy 51 link tiếp theo\n",
    "MAX_SENTENCES = 20  # Giới hạn 20 câu mỗi bài\n",
    "\n",
    "print(f\" File Input: {input_file_path}\")\n",
    "print(f\" File Output (Ghi tiếp): {output_file_path}\")\n",
    "print(f\" Bỏ qua: {SKIP_COUNT} link.\")\n",
    "print(f\" Xử lý tiếp: {TAKE_COUNT} link.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6591b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_and_process(url, source_name):\n",
    "    sentences_data = []\n",
    "    try:\n",
    "        decoded_url = urllib.parse.unquote(url)\n",
    "        \n",
    "        response = requests.get(decoded_url, headers=HEADERS, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            print(f\" Lỗi HTTP {response.status_code}\")\n",
    "            return []\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        content_div = soup.find('div', {'id': 'mw-content-text'})\n",
    "        if not content_div:\n",
    "            return []\n",
    "\n",
    "        paragraphs = content_div.find_all('p')\n",
    "        \n",
    "        collected_count = 0\n",
    "        \n",
    "        for p in paragraphs:\n",
    "            if collected_count >= MAX_SENTENCES:\n",
    "                break\n",
    "                \n",
    "            text = p.get_text()\n",
    "            \n",
    "            text = re.sub(r'\\[\\d+\\]', '', text) # Xóa [1]\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            \n",
    "            if not text: continue\n",
    "            \n",
    "            sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "            \n",
    "            for sent in sentences:\n",
    "                if collected_count >= MAX_SENTENCES:\n",
    "                    break\n",
    "                \n",
    "                if len(sent) > 15:\n",
    "                    clean_sent = sent.strip()\n",
    "                    \n",
    "                    sentences_data.append({\n",
    "                        \"ten_tac_gia\": source_name, # Dùng key 'ten_tac_gia' để đồng bộ với phần 1 (hoặc 'source' tùy bạn)\n",
    "                        \"cau_van\": clean_sent,\n",
    "                    })\n",
    "                    collected_count += 1\n",
    "                    \n",
    "        return sentences_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Lỗi Exception: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a556225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sẽ xử lý từ link thứ 58 đến 108.\n",
      " Không có dữ liệu mới nào được thêm vào.\n"
     ]
    }
   ],
   "source": [
    "new_items_count = 0\n",
    "\n",
    "if os.path.exists(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    valid_links = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(',') if ',' in line else line.strip().split(';')\n",
    "        if len(parts) >= 2 and \"http\" in parts[-1]:\n",
    "            name = parts[0].strip().replace('\"', '')\n",
    "            url = parts[-1].strip().replace('\"', '')\n",
    "            valid_links.append((name, url))\n",
    "\n",
    "    start_index = SKIP_COUNT\n",
    "    end_index = SKIP_COUNT + TAKE_COUNT\n",
    "    target_links = valid_links[start_index:end_index]\n",
    "    \n",
    "    print(f\" Sẽ xử lý từ link thứ {start_index+1} đến {end_index}.\")\n",
    "\n",
    "    for i, (name, url) in enumerate(target_links):\n",
    "        print(f\"[{i+1}/{len(target_links)}] ⏳ {name}...\", end=\" \")\n",
    "        \n",
    "        data = scrape_and_process(url, name)\n",
    "        \n",
    "        if data:\n",
    "            new_items_count += len(data)\n",
    "            print(f\" Thêm {len(data)} câu.\")\n",
    "        else:\n",
    "            print(\" Không lấy được câu nào.\")\n",
    "            \n",
    "        time.sleep(0.2) \n",
    "\n",
    "    if new_items_count > 0:\n",
    "        print(f\"\\n Đang lưu tổng cộng: {output_file_path}\")\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        print(\" HOÀN TẤT! Dữ liệu đã được cập nhật.\")\n",
    "    else:\n",
    "        print(\" Không có dữ liệu mới nào được thêm vào.\")\n",
    "\n",
    "else:\n",
    "    print(f\" Không tìm thấy file input tại: {input_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49931b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " File 1: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\wiki_sentences_1.json\n",
      " File 2: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\wiki_sentences_2.json\n",
      " File Output: d:\\STUDY DOCUMENT\\4th YEAR\\NLP\\Vietnamese_literature\\Data\\final_dataset.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_folder = os.getcwd()\n",
    "data_folder_path = os.path.abspath(os.path.join(current_folder, '..', 'Data'))\n",
    "\n",
    "file_path_1 = os.path.join(data_folder_path, 'wiki_sentences_1.json') \n",
    "\n",
    "file_path_2 = os.path.join(data_folder_path, 'wiki_sentences_2.json')\n",
    "\n",
    "# File đầu ra\n",
    "output_file_path = os.path.join(data_folder_path, 'final_dataset.json')\n",
    "\n",
    "print(f\" File 1: {file_path_1}\")\n",
    "print(f\" File 2: {file_path_2}\")\n",
    "print(f\" File Output: {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38d10f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CẢNH BÁO: Không tìm thấy file wiki_sentences_1.json\n",
      "\n",
      " CẢNH BÁO: Không tìm thấy file wiki_sentences_2.json\n"
     ]
    }
   ],
   "source": [
    "final_dataset = []\n",
    "current_id = 1\n",
    "\n",
    "# Danh sách các file cần gộp\n",
    "files_to_merge = [file_path_1, file_path_2]\n",
    "\n",
    "for file_path in files_to_merge:\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            print(f\"   -> Tìm thấy {len(data)} dòng dữ liệu.\")\n",
    "            \n",
    "            count_added = 0\n",
    "            for entry in data:\n",
    "                text = entry.get('cau_van')\n",
    "                \n",
    "                if not text:\n",
    "                    text = entry.get('text')\n",
    "\n",
    "                if text:\n",
    "                    # Tạo cấu trúc mới chỉ gồm ID và Text\n",
    "                    new_entry = {\n",
    "                        \"id\": current_id,\n",
    "                        \"text\": text.strip() \n",
    "                    }\n",
    "                    final_dataset.append(new_entry)\n",
    "                    current_id += 1\n",
    "                    count_added += 1\n",
    "            \n",
    "            print(f\" Đã thêm {count_added} câu vào danh sách chung.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Lỗi khi đọc file: {e}\")\n",
    "    else:\n",
    "        print(f\"\\n CẢNH BÁO: Không tìm thấy file {os.path.basename(file_path)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8913f15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Không có dữ liệu nào được gộp.\n"
     ]
    }
   ],
   "source": [
    "if final_dataset:\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_dataset, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    # Xem thử mẫu 3 dòng đầu\n",
    "    print(json.dumps(final_dataset[:3], ensure_ascii=False, indent=4))\n",
    "else:\n",
    "    print(\"\\n Không có dữ liệu nào được gộp.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33760be",
   "metadata": {},
   "source": [
    "# xóa các file không còn cần thiết "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdeba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files_to_delete = [\n",
    "    \"wiki_data.json\",                # File dữ liệu thô ban đầu\n",
    "    \"wiki_data2.json\",           # File tách câu thử nghiệm\n",
    "    \"wiki_sentences_1.json\",  # File kết quả phần 1\n",
    "    \"wiki_sentences_2.json\",     # File kết quả phần 2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fde5845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã xóa: wiki_data.json\n",
      " Không tìm thấy file (có thể đã xóa rồi): wiki_data2.json\n",
      " Không tìm thấy file (có thể đã xóa rồi): wiki_sentences_1.json\n",
      " Không tìm thấy file (có thể đã xóa rồi): wiki_sentences_2.json\n",
      "\n",
      " HOÀN TẤT DỌN DẸP!\n"
     ]
    }
   ],
   "source": [
    "for file_name in files_to_delete:\n",
    "    file_path = os.path.join(data_folder_path, file_name)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            os.remove(file_path) # Lệnh xóa file\n",
    "            print(f\"Đã xóa: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Lỗi khi xóa {file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\" Không tìm thấy file (có thể đã xóa rồi): {file_name}\")\n",
    "\n",
    "print(\"\\n HOÀN TẤT DỌN DẸP!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
